{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison Lab\n",
    "\n",
    "In this lab we will compare the performance of all the models we have learned about so far, using the car evaluation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the data\n",
    "\n",
    "The [car evaluation dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/car/) is in the assets/datasets folder. By now you should be very familiar with this dataset.\n",
    "\n",
    "1. Load the data into a pandas dataframe\n",
    "- Encode the categorical features properly: define a map that preserves the scale (assigning smaller numbers to words indicating smaller quantities)\n",
    "- Separate features from target into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>acceptability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety acceptability\n",
       "0  vhigh  vhigh     2       2    small    low         unacc\n",
       "1  vhigh  vhigh     2       2    small    med         unacc\n",
       "2  vhigh  vhigh     2       2    small   high         unacc\n",
       "3  vhigh  vhigh     2       2      med    low         unacc\n",
       "4  vhigh  vhigh     2       2      med    med         unacc"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data into a pandas dataframe\n",
    "df = pd.read_csv('../../assets/datasets/car.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = df['acceptability']\n",
    "le.fit(y)\n",
    "y = le.transform(y)\n",
    "\n",
    "# # Encode categorical features to booleans\n",
    "# X = pd.get_dummies(df[['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>acceptability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying  maint  doors  persons  lug_boot  safety acceptability\n",
       "0       4      4      1        1         1       1         unacc\n",
       "1       4      4      1        1         1       2         unacc\n",
       "2       4      4      1        1         1       3         unacc\n",
       "3       4      4      1        1         2       1         unacc\n",
       "4       4      4      1        1         2       2         unacc"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_maint = {'vhigh': 4,'high': 3,'med': 2,'low':1}\n",
    "map_doors = {'5more': 4,'4': 3,'3': 2,'2':1}\n",
    "map_persons = {'more': 3,'4': 2,'2':1}\n",
    "map_lug_boot = {'big': 3,'med': 2,'small':1}\n",
    "map_safety = {'high': 3,'med': 2,'low':1}\n",
    "\n",
    "df.maint = df.maint.map(map_maint)\n",
    "df.buying = df.buying.map(map_maint)\n",
    "df.doors = df.doors.map(map_doors)\n",
    "df.persons = df.persons.map(map_persons)\n",
    "df.lug_boot = df.lug_boot.map(map_lug_boot)\n",
    "df.safety = df.safety.map(map_safety)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Useful preparation\n",
    "\n",
    "Since we will compare several models, let's write a couple of helper functions.\n",
    "\n",
    "1. Separate X and y between a train and test set, using 30% test set, random state = 42\n",
    "    - make sure that the data is shuffled and stratified\n",
    "2. Define a function called `evaluate_model`, that trains the model on the train set, tests it on the test, calculates:\n",
    "    - accuracy score\n",
    "    - confusion matrix\n",
    "    - classification report\n",
    "3. Initialize a global dictionary to store the various models for later retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Separate X and y between a train and test set, using 30% test set, random state = 42\n",
    "#make sure that the data is shuffled and stratified\n",
    "#cv = StratifiedKFold(y, n_folds=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.drop('acceptability', axis=1)\n",
    "y = df.acceptability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define a function called evaluate_model, that trains the model on the train set, tests it on the test, calculates:\n",
    "\n",
    "def evaluate_model(model, name):\n",
    "    s = cross_val_score(model, X, y, cv=3, n_jobs=-1)\n",
    "    print \"{} Cross Val Score:\\t{:0.3} ± {:0.3}\".format(name, s.mean().round(3), s.std().round(3))\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print \"Accuracy: \", model.score(X_test,y_test)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred, labels =['unacc','acc','good', 'vgood'] ) \n",
    "    print pd.DataFrame(cm, index=['True unacc','True acc','True good', 'True vgood'], \n",
    "                       columns=['Pred unacc','Pred acc','Pred good', 'Pred vgood'] )\n",
    "    print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize a global dictionary to store the various models for later retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.a KNN\n",
    "\n",
    "Let's start with `KNeighborsClassifier`.\n",
    "\n",
    "1. Initialize a KNN model\n",
    "- Evaluate it's performance with the function you previously defined\n",
    "- Find the optimal value of K using grid search\n",
    "    - Be careful on how you perform the cross validation in the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn Cross Val Score:\t0.739 ± 0.123\n",
      "Accuracy:  0.946050096339\n",
      "            Pred unacc  Pred acc  Pred good  Pred vgood\n",
      "True unacc         355         8          0           0\n",
      "True acc            12       103          0           0\n",
      "True good            0         2         19           0\n",
      "True vgood           0         4          2          14\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.88      0.90      0.89       115\n",
      "       good       0.90      0.90      0.90        21\n",
      "      unacc       0.97      0.98      0.97       363\n",
      "      vgood       1.00      0.70      0.82        20\n",
      "\n",
      "avg / total       0.95      0.95      0.95       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "evaluate_model(knn, 'knn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dnay/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.773148148148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 9}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "parameters = {\"n_neighbors\": [1,2,3,4,5,6,7,8,9,10]}\n",
    "\n",
    "gs = GridSearchCV(knn, parameters, cv=5, n_jobs=4)\n",
    "gs.fit(X, y)\n",
    "print gs.best_score_\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn with grid Search Cross Val Score:\t0.775 ± 0.103\n",
      "Accuracy:  0.942196531792\n",
      "            Pred unacc  Pred acc  Pred good  Pred vgood\n",
      "True unacc         357         6          0           0\n",
      "True acc            13       102          0           0\n",
      "True good            2         4         15           0\n",
      "True vgood           1         3          1          15\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.89      0.89      0.89       115\n",
      "       good       0.94      0.71      0.81        21\n",
      "      unacc       0.96      0.98      0.97       363\n",
      "      vgood       1.00      0.75      0.86        20\n",
      "\n",
      "avg / total       0.94      0.94      0.94       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "\n",
    "evaluate_model(knn, 'knn with grid Search')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.b Bagging + KNN\n",
    "\n",
    "Now that we have found the optimal K, let's wrap `KNeighborsClassifier` in a BaggingClassifier and see if the score improves.\n",
    "\n",
    "1. Wrap the KNN model in a Bagging Classifier\n",
    "- Evaluate performance\n",
    "- Do a grid search only on the bagging classifier params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dnay/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/Users/dnay/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/Users/dnay/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn with bagging Cross Val Score:\t0.742 ± 0.128\n",
      "Accuracy:  0.940269749518\n",
      "            Pred unacc  Pred acc  Pred good  Pred vgood\n",
      "True unacc         354         9          0           0\n",
      "True acc            12       102          1           0\n",
      "True good            2         2         16           1\n",
      "True vgood           0         2          2          16\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.89      0.89      0.89       115\n",
      "       good       0.84      0.76      0.80        21\n",
      "      unacc       0.96      0.98      0.97       363\n",
      "      vgood       0.94      0.80      0.86        20\n",
      "\n",
      "avg / total       0.94      0.94      0.94       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "Bknn = BaggingClassifier(knn)\n",
    "\n",
    "evaluate_model(Bknn, 'knn with bagging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77025462963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'bootstrap_features': False,\n",
       " 'max_features': 4,\n",
       " 'n_estimators': 3}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\"n_estimators\": [1, 3, 5, 7, 9, 11],\n",
    "              'max_features': [1, 2, 3, 4, 5],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"bootstrap_features\": [True, False]}\n",
    "gs = GridSearchCV(Bknn, parameters, cv=5, n_jobs=1)\n",
    "gs.fit(X, y)\n",
    "print gs.best_score_\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dnay/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/Users/dnay/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/Users/dnay/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn with bagging and bets params Cross Val Score:\t0.738 ± 0.015\n",
      "Accuracy:  0.761078998073\n",
      "            Pred unacc  Pred acc  Pred good  Pred vgood\n",
      "True unacc         353        10          0           0\n",
      "True acc            68        40          4           3\n",
      "True good            5        15          1           0\n",
      "True vgood           7        12          0           1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.52      0.35      0.42       115\n",
      "       good       0.20      0.05      0.08        21\n",
      "      unacc       0.82      0.97      0.89       363\n",
      "      vgood       0.25      0.05      0.08        20\n",
      "\n",
      "avg / total       0.70      0.76      0.72       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Bknn = BaggingClassifier(knn,bootstrap = True,\n",
    " bootstrap_features = False,\n",
    " max_features = 4,\n",
    " n_estimators = 3)\n",
    "\n",
    "evaluate_model(Bknn, 'knn with bagging and bets params')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic Regression\n",
    "\n",
    "Let's see if logistic regression performs better\n",
    "\n",
    "1. Initialize LR and test on Train/Test set\n",
    "- Find optimal params with Grid Search\n",
    "- See if Bagging improves the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log reg Cross Val Score:\t0.707 ± 0.075\n",
      "Accuracy:  0.782273603083\n",
      "            Pred unacc  Pred acc  Pred good  Pred vgood\n",
      "True unacc         351         9          0           3\n",
      "True acc            64        49          2           0\n",
      "True good            4        10          3           4\n",
      "True vgood           0        17          0           3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.58      0.43      0.49       115\n",
      "       good       0.60      0.14      0.23        21\n",
      "      unacc       0.84      0.97      0.90       363\n",
      "      vgood       0.30      0.15      0.20        20\n",
      "\n",
      "avg / total       0.75      0.78      0.75       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "evaluate_model(lr, 'Log reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754050925926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]}\n",
    "\n",
    "gs = GridSearchCV(LR, parameters, cv=5, n_jobs=1)\n",
    "gs.fit(X, y)\n",
    "print gs.best_score_\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dnay/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/Users/dnay/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/Users/dnay/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Logistic Regression Cross Val Score:\t0.707 ± 0.101\n",
      "Accuracy:  0.803468208092\n",
      "            Pred unacc  Pred acc  Pred good  Pred vgood\n",
      "True unacc         350        12          1           0\n",
      "True acc            59        54          2           0\n",
      "True good            5        10          6           0\n",
      "True vgood           0        13          0           7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.61      0.47      0.53       115\n",
      "       good       0.67      0.29      0.40        21\n",
      "      unacc       0.85      0.96      0.90       363\n",
      "      vgood       1.00      0.35      0.52        20\n",
      "\n",
      "avg / total       0.79      0.80      0.78       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C= 1.0, penalty='l1')\n",
    "blr = BaggingClassifier(lr)\n",
    "evaluate_model(blr, 'Bagging Logistic Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Decision Trees\n",
    "\n",
    "Let's see if Decision Trees perform better\n",
    "\n",
    "1. Initialize DT and test on Train/Test set\n",
    "- Find optimal params with Grid Search\n",
    "- See if Bagging improves the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Cross Val Score:\t0.818 ± 0.013\n",
      "Accuracy:  0.982658959538\n",
      "            Pred unacc  Pred acc  Pred good  Pred vgood\n",
      "True unacc         360         3          0           0\n",
      "True acc             3       110          2           0\n",
      "True good            0         0         21           0\n",
      "True vgood           0         1          0          19\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.96      0.96      0.96       115\n",
      "       good       0.91      1.00      0.95        21\n",
      "      unacc       0.99      0.99      0.99       363\n",
      "      vgood       1.00      0.95      0.97        20\n",
      "\n",
      "avg / total       0.98      0.98      0.98       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "evaluate_model(dt, \"Decision Tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.857060185185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 8,\n",
       " 'max_features': 4,\n",
       " 'max_leaf_nodes': None}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_features': [None, 1, 2, 3,4,5],\n",
    "    'max_depth': [None, 4, 5, 6, 7, 8, 9],\n",
    "    'max_leaf_nodes': [None, 4, 5, 6, 7, 8, 9]\n",
    "}\n",
    "gs = GridSearchCV(DT, parameters, cv=5, n_jobs=1)\n",
    "gs.fit(X, y)\n",
    "print gs.best_score_\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Decision Tree Cross Val Score:\t0.815 ± 0.01\n",
      "Accuracy:  0.982658959538\n",
      "            Pred unacc  Pred acc  Pred good  Pred vgood\n",
      "True unacc         360         3          0           0\n",
      "True acc             3       110          2           0\n",
      "True good            0         0         21           0\n",
      "True vgood           0         1          0          19\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.96      0.96      0.96       115\n",
      "       good       0.91      1.00      0.95        21\n",
      "      unacc       0.99      0.99      0.99       363\n",
      "      vgood       1.00      0.95      0.97        20\n",
      "\n",
      "avg / total       0.98      0.98      0.98       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "bdt = BaggingClassifier(dt)\n",
    "evaluate_model(dt, 'Bagging Decision Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Support Vector Machines\n",
    "\n",
    "Let's see if SVM perform better\n",
    "\n",
    "1. Initialize SVM and test on Train/Test set\n",
    "- Find optimal params with Grid Search\n",
    "- See if Bagging improves the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support vector machine Cross Val Score:\t0.764 ± 0.113\n",
      "Accuracy:  0.957610789981\n",
      "            Pred unacc  Pred acc  Pred good  Pred vgood\n",
      "True unacc         352        11          0           0\n",
      "True acc             7       108          0           0\n",
      "True good            0         2         19           0\n",
      "True vgood           0         1          1          18\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.89      0.94      0.91       115\n",
      "       good       0.95      0.90      0.93        21\n",
      "      unacc       0.98      0.97      0.98       363\n",
      "      vgood       1.00      0.90      0.95        20\n",
      "\n",
      "avg / total       0.96      0.96      0.96       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "sv = SVC()\n",
    "evaluate_model(sv, \"Support vector machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dnay/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/Users/dnay/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/Users/dnay/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Support vector machine Cross Val Score:\t0.767 ± 0.11\n",
      "Accuracy:  0.946050096339\n",
      "            Pred unacc  Pred acc  Pred good  Pred vgood\n",
      "True unacc         352        11          0           0\n",
      "True acc             9       105          0           1\n",
      "True good            0         4         17           0\n",
      "True vgood           0         1          2          17\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.87      0.91      0.89       115\n",
      "       good       0.89      0.81      0.85        21\n",
      "      unacc       0.98      0.97      0.97       363\n",
      "      vgood       0.94      0.85      0.89        20\n",
      "\n",
      "avg / total       0.95      0.95      0.95       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bsv = BaggingClassifier(sv)\n",
    "evaluate_model(bsv, \"Bagging Support vector machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.707175925926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "gs = GridSearchCV(sv, parameters, n_jobs=2)\n",
    "gs.fit(X, y)\n",
    "print gs.best_score_\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94219653179190754"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv = SVC(gamma=0.001, C=10000, kernel='rbf', degree=5)\n",
    "\n",
    "bsv = BaggingClassifier(sv)\n",
    "bsv.fit(X_train,y_train)\n",
    "\n",
    "bsv.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Random Forest & Extra Trees\n",
    "\n",
    "Let's see if Random Forest and Extra Trees perform better\n",
    "\n",
    "1. Initialize RF and ET and test on Train/Test set\n",
    "- Find optimal params with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Cross Val Score:\t0.819 ± 0.029\n",
      "Accuracy:  0.957610789981\n",
      "            Pred unacc  Pred acc  Pred good  Pred vgood\n",
      "True unacc         352        11          0           0\n",
      "True acc             4       111          0           0\n",
      "True good            0         2         19           0\n",
      "True vgood           0         3          2          15\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.87      0.97      0.92       115\n",
      "       good       0.90      0.90      0.90        21\n",
      "      unacc       0.99      0.97      0.98       363\n",
      "      vgood       1.00      0.75      0.86        20\n",
      "\n",
      "avg / total       0.96      0.96      0.96       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "evaluate_model(rfc, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.864583333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True, 'criterion': 'entropy', 'max_depth': 11, 'max_features': 6}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {\n",
    "    'bootstrap': [True, False],\n",
    "    'criterion':['gini', 'entropy'],\n",
    "    'max_features': [1, 2, 3, 4,5,6],\n",
    "    'max_depth': [None, 3, 5, 7, 9, 11,13, 15,17]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(rfc, param,cv=5, n_jobs=2)\n",
    "gs.fit(X, y)\n",
    "print gs.best_score_\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Cross Val Score:\t0.833 ± 0.054\n",
      "Accuracy:  0.97880539499\n",
      "            Pred unacc  Pred acc  Pred good  Pred vgood\n",
      "True unacc         359         4          0           0\n",
      "True acc             6       108          1           0\n",
      "True good            0         0         21           0\n",
      "True vgood           0         0          0          20\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.96      0.94      0.95       115\n",
      "       good       0.95      1.00      0.98        21\n",
      "      unacc       0.98      0.99      0.99       363\n",
      "      vgood       1.00      1.00      1.00        20\n",
      "\n",
      "avg / total       0.98      0.98      0.98       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(bootstrap = True,\n",
    " criterion= 'entropy',\n",
    " max_depth = 11,\n",
    " max_features = 6)\n",
    "\n",
    "evaluate_model(rfc, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Tree Classfifier Cross Val Score:\t0.855 ± 0.001\n",
      "Accuracy:  0.957610789981\n",
      "            Pred unacc  Pred acc  Pred good  Pred vgood\n",
      "True unacc         350        13          0           0\n",
      "True acc             4       109          1           1\n",
      "True good            0         2         19           0\n",
      "True vgood           0         1          0          19\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.87      0.95      0.91       115\n",
      "       good       0.95      0.90      0.93        21\n",
      "      unacc       0.99      0.96      0.98       363\n",
      "      vgood       0.95      0.95      0.95        20\n",
      "\n",
      "avg / total       0.96      0.96      0.96       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "etc = ExtraTreesClassifier()\n",
    "evaluate_model(etc, \"Extra Tree Classfifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.869212962963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': None,\n",
       " 'max_features': 3}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {\n",
    "    'bootstrap': [True, False],\n",
    "    'criterion':['gini', 'entropy'],\n",
    "    'max_features': [1, 2, 3, 4,5,6],\n",
    "    'max_depth': [None, 3, 5, 7, 9,11,13, 15,17]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(rfc, param,cv=5, n_jobs=2)\n",
    "gs.fit(X, y)\n",
    "print gs.best_score_\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Tree Classfifier Cross Val Score:\t0.835 ± 0.037\n",
      "Accuracy:  0.974951830443\n",
      "            Pred unacc  Pred acc  Pred good  Pred vgood\n",
      "True unacc         356         7          0           0\n",
      "True acc             3       111          0           1\n",
      "True good            0         1         20           0\n",
      "True vgood           0         0          1          19\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.93      0.97      0.95       115\n",
      "       good       0.95      0.95      0.95        21\n",
      "      unacc       0.99      0.98      0.99       363\n",
      "      vgood       0.95      0.95      0.95        20\n",
      "\n",
      "avg / total       0.98      0.97      0.98       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "etc = ExtraTreesClassifier(bootstrap = True,max_depth= None,\n",
    " criterion= 'entropy',\n",
    " max_features = 6)\n",
    "\n",
    "evaluate_model(etc, \"Extra Tree Classfifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model comparison\n",
    "\n",
    "Let's compare the scores of the various models.\n",
    "\n",
    "1. Do a bar chart of the scores of the best models. Who's the winner on the train/test split?\n",
    "- Re-test all the models using a 3 fold stratified shuffled cross validation\n",
    "- Do a bar chart with errorbars of the cross validation average scores. is the winner the same?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is RandomForestClassifier with Parameters from GridSearch\n",
      "\n",
      "Random Forest Cross Val Score:\t0.829 ± 0.053\n",
      "Accuracy:  0.986512524085\n",
      "            Pred unacc  Pred acc  Pred good  Pred vgood\n",
      "True unacc         360         3          0           0\n",
      "True acc             0       115          0           0\n",
      "True good            0         1         20           0\n",
      "True vgood           0         1          2          17\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.96      1.00      0.98       115\n",
      "       good       0.91      0.95      0.93        21\n",
      "      unacc       1.00      0.99      1.00       363\n",
      "      vgood       1.00      0.85      0.92        20\n",
      "\n",
      "avg / total       0.99      0.99      0.99       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"The best model is RandomForestClassifier with Parameters from GridSearch\\n\"\n",
    "evaluate_model(rfc, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "We have encoded the data using a map that preserves the scale.\n",
    "Would our results have changed if we had encoded the categorical data using `pd.get_dummies` or `OneHotEncoder`  to encode them as binary variables instead?\n",
    "\n",
    "1. Repeat the analysis for this scenario. Is it better?\n",
    "- Experiment with other models or other parameters, can you beat your classmates best score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
